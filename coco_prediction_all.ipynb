{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('/opt/cocoapi/PythonAPI')\n",
    "from pycocotools.coco import COCO\n",
    "from torchvision import transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os, shutil, glob, os.path\n",
    "from collections import defaultdict \n",
    "import torch\n",
    "from model import EncoderCNN, DecoderRNN\n",
    "from data_loader import get_loader\n",
    "import matplotlib\n",
    "matplotlib.use('tkagg')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "maindir = 'E:/insta filter/#covid_19/'\n",
    "folder =[]\n",
    "os.chdir(maindir)\n",
    "#Determining the country code in the folder\n",
    "for name in os.listdir(\".\"):\n",
    "    if os.path.isdir(name+'/vgg16/'):\n",
    "        folder.append(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "transform_test = transforms.Compose([ \n",
    "    transforms.Resize(256),                          \n",
    "    transforms.RandomCrop(224),                      \n",
    "    transforms.RandomHorizontalFlip(),               \n",
    "    transforms.ToTensor(),                           \n",
    "    transforms.Normalize((0.485, 0.456, 0.406),      \n",
    "                         (0.229, 0.224, 0.225))])\n",
    "\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "\n",
    "encoder_file = 'encoder-3.pkl'\n",
    "decoder_file = 'decoder-3.pkl'\n",
    "\n",
    "embed_size = 256\n",
    "hidden_size = 512"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df= pd.DataFrame(columns=['country_code','sentence','cluster_no'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "AE\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  6\n",
      "AR\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  7\n",
      "AT\n",
      "image number :  100  of cluster:  2\n",
      "AU\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  7\n",
      "image number :  100  of cluster:  9\n",
      "BE\n",
      "image number :  100  of cluster:  1\n",
      "BO\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "BR\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  9\n",
      "CA\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  5\n",
      "CH\n",
      "image number :  100  of cluster:  0\n",
      "CL\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  7\n",
      "CN\n",
      "image number :  100  of cluster:  0\n",
      "CO\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  9\n",
      "CZ\n",
      "image number :  100  of cluster:  2\n",
      "DE\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  9\n",
      "DK\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  5\n",
      "DO\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "DZ\n",
      "EC\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  6\n",
      "EG\n",
      "image number :  100  of cluster:  2\n",
      "ES\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  9\n",
      "FR\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "GB\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  8\n",
      "image number :  100  of cluster:  9\n",
      "GH\n",
      "image number :  100  of cluster:  4\n",
      "GR\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  5\n",
      "GT\n",
      "image number :  100  of cluster:  5\n",
      "HK\n",
      "image number :  100  of cluster:  2\n",
      "ID\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  7\n",
      "IE\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  6\n",
      "IL\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  7\n",
      "IN\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  8\n",
      "IQ\n",
      "image number :  100  of cluster:  0\n",
      "IR\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  9\n",
      "IT\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  9\n",
      "JO\n",
      "image number :  100  of cluster:  2\n",
      "JP\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  9\n",
      "KE\n",
      "image number :  100  of cluster:  3\n",
      "KR\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  7\n",
      "KZ\n",
      "image number :  100  of cluster:  3\n",
      "LB\n",
      "image number :  100  of cluster:  3\n",
      "MA\n",
      "image number :  100  of cluster:  1\n",
      "MX\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  7\n",
      "MY\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  6\n",
      "NG\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  1\n",
      "NL\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "NZ\n",
      "PA\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "PE\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  7\n",
      "PH\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "PK\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  7\n",
      "image number :  100  of cluster:  8\n",
      "PL\n",
      "image number :  100  of cluster:  5\n",
      "PR\n",
      "image number :  100  of cluster:  5\n",
      "PT\n",
      "image number :  100  of cluster:  1\n",
      "RU\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  7\n",
      "image number :  100  of cluster:  9\n",
      "SA\n",
      "image number :  100  of cluster:  2\n",
      "SE\n",
      "image number :  100  of cluster:  1\n",
      "SG\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  5\n",
      "TH\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  6\n",
      "TR\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  5\n",
      "TW\n",
      "image number :  100  of cluster:  1\n",
      "UA\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  4\n",
      "image number :  100  of cluster:  6\n",
      "unknown\n",
      "image number :  100  of cluster:  0\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  9\n",
      "US\n",
      "image number :  100  of cluster:  1\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  6\n",
      "UY\n",
      "image number :  100  of cluster:  0\n",
      "VE\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  6\n",
      "image number :  100  of cluster:  8\n",
      "image number :  100  of cluster:  9\n",
      "ZA\n",
      "image number :  100  of cluster:  2\n",
      "image number :  100  of cluster:  3\n",
      "image number :  100  of cluster:  5\n",
      "image number :  100  of cluster:  9\n"
     ]
    }
   ],
   "source": [
    "data_loader = get_loader(transform=transform_test, mode='test',ipath='12.jpg')\n",
    "vocab_size = len(data_loader.dataset.vocab)\n",
    "encoder = EncoderCNN(embed_size)\n",
    "encoder.eval()\n",
    "decoder = DecoderRNN(embed_size, hidden_size, vocab_size)\n",
    "decoder.eval()\n",
    "\n",
    "encoder.load_state_dict(torch.load(os.path.join('D:/Projectinsta/models', encoder_file),map_location=torch.device('cpu')))\n",
    "decoder.load_state_dict(torch.load(os.path.join('D:/Projectinsta/models', decoder_file),map_location=torch.device('cpu')))\n",
    "\n",
    "encoder.to(device)\n",
    "decoder.to(device)\n",
    "\n",
    "def clean_sentence(output):\n",
    "    sentence = ''\n",
    "    new_output = output[1:-1] \n",
    "    for i in range(len(new_output)):\n",
    "        curr_token = new_output[i]\n",
    "        if curr_token == 18: sentence += data_loader.dataset.vocab.idx2word[curr_token]\n",
    "        else: sentence += ' ' + data_loader.dataset.vocab.idx2word[curr_token]\n",
    "    return sentence\n",
    "\n",
    "for i in folder:\n",
    "    print(i)\n",
    "    sdir= maindir + i + '/vgg16/'\n",
    "    filelist = glob.glob(os.path.join(sdir, '*.jpg'))\n",
    "    #print(filelist[0])\n",
    "    file_dict={}\n",
    "    for image in filelist:\n",
    "        sample=image\n",
    "        key = (sample.split('\\\\')[-1]).split('_')[0]\n",
    "        if key not in file_dict.keys():\n",
    "            file_dict[key]=[]\n",
    "        file_dict[key].append(image)\n",
    "    #print(file_dict.keys())\n",
    "    #captions_dict={}\n",
    "    #mydic={}\n",
    "    for key, value in file_dict.items():\n",
    "        cluster=[]\n",
    "        count = 0\n",
    "        for j in range(len(value)):\n",
    "            data_loader = get_loader(transform=transform_test, mode='test',cocoapi_loc=str(sdir),ipath = str(value[j].split('\\\\')[1]))\n",
    "            orig_image, image = next(iter(data_loader))\n",
    "            image = image.to(device)\n",
    "            features = encoder(image).unsqueeze(1)\n",
    "            output = decoder.sample(features)\n",
    "            sentence = clean_sentence(output)\n",
    "            df=df.append({'country_code':i,'sentence':sentence,'cluster_no':key},ignore_index=True)\n",
    "            if j==100:\n",
    "                print('image number : ', j , ' of cluster: ',key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv (r'D:\\Projectinsta\\coco_captions1.csv', header=True, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
